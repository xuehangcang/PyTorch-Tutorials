{"cells":[{"cell_type":"markdown","metadata":{"id":"525A33EE274147BBA33663EBB2E28BD3","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"<a href=\"https://github.com/xuehangcang/DeepLearning/blob/main/docs/PyTorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/1.%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8.ipynb\" download=\"\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"110\" height=\"20\" role=\"img\" aria-label=\"jupyter: notebook\"><title>jupyter: notebook</title><linearGradient id=\"s\" x2=\"0\" y2=\"100%\"><stop offset=\"0\" stop-color=\"#bbb\" stop-opacity=\".1\"/><stop offset=\"1\" stop-opacity=\".1\"/></linearGradient><clipPath id=\"r\"><rect width=\"110\" height=\"20\" rx=\"3\" fill=\"#fff\"/></clipPath><g clip-path=\"url(#r)\"><rect width=\"49\" height=\"20\" fill=\"#555\"/><rect x=\"49\" width=\"61\" height=\"20\" fill=\"#fe7d37\"/><rect width=\"110\" height=\"20\" fill=\"url(#s)\"/></g><g fill=\"#fff\" text-anchor=\"middle\" font-family=\"Verdana,Geneva,DejaVu Sans,sans-serif\" text-rendering=\"geometricPrecision\" font-size=\"110\"><text aria-hidden=\"true\" x=\"255\" y=\"150\" fill=\"#010101\" fill-opacity=\".3\" transform=\"scale(.1)\" textLength=\"390\">jupyter</text><text x=\"255\" y=\"140\" transform=\"scale(.1)\" fill=\"#fff\" textLength=\"390\">jupyter</text><text aria-hidden=\"true\" x=\"785\" y=\"150\" fill=\"#010101\" fill-opacity=\".3\" transform=\"scale(.1)\" textLength=\"510\">notebook</text><text x=\"785\" y=\"140\" transform=\"scale(.1)\" fill=\"#fff\" textLength=\"510\">notebook</text></g></svg></a>"},{"cell_type":"markdown","metadata":{"id":"EFCBC3DB15C5486E9DDEB3F6F0E282FB","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"## 1.1 基础知识  \n\n大多数机器学习工作流都涉及到处理数据、创建模型、优化模型参数以及保存训练好的模型。本教程介绍了如何在PyTorch中实现完整的机器学习工作流，并提供了相关概念的学习链接。  \n\n我们将使用FashionMNIST数据集来训练一个神经网络，该网络可以预测输入图像属于以下哪个类别：T恤/上衣、裤子、套衫、连衣裙、外套、凉鞋、衬衫、运动鞋、包或踝靴。  \n\n本教程假设你已经基础了解Python和深度学习的概念。"},{"cell_type":"markdown","metadata":{"id":"8C544689311F4BBB911E4997D11A2E54","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"## 1.2 处理数据  \n\nPyTorch有两个与数据处理相关的基本元素：`torch.utils.data.DataLoader` 和 `torch.utils.data.Dataset`。  \n`Dataset` 存储样本及其对应的标签，而 `DataLoader` 则在 `Dataset` 周围建立一个可迭代的包装器。"},{"cell_type":"code","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2023-04-22T03:05:40.498817Z","end_time":"2023-04-22T03:05:40.511646Z"},"id":"0BE7B27EBC53412685869E208ECC1A90","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3","trusted":true},"source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor","outputs":[],"execution_count":3},{"cell_type":"markdown","metadata":{"id":"D260BBF1A4D74BEC9FF29228C77CCB71","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"PyTorch提供了特定领域的库，例如TorchText、TorchVision和TorchAudio，它们都包含数据集。在本教程中，我们将使用一个TorchVision数据集。  \n\ntorchvision.datasets模块包含许多现实世界的视觉数据集，如CIFAR、COCO。在本教程中，我们将使用FashionMNIST数据集。每个TorchVision数据集都包括两个参数：transform和target_transform，分别用于修改样本和标签。"},{"cell_type":"code","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2023-04-22T03:07:11.883967Z","end_time":"2023-04-22T03:07:32.162237Z"},"id":"EDF1CE9872104B439BB9121B4272211D","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3","trusted":true},"source":"# 从开放数据集中下载训练数据\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)\n\n# 从开放数据集中下载测试数据\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)","outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100.0%"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":4},{"cell_type":"markdown","metadata":{"id":"2794EEB7547545CB961CA908170071D1","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"我们将`Dataset`作为参数传递给`DataLoader`。这将包装我们的数据集为一个迭代器，并支持自动批处理、采样、洗牌和多进程数据加载。在这里，我们定义批次大小为64，即数据加载器迭代器中的每个元素将返回 64 个特征和标签的批次。"},{"cell_type":"code","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2023-04-22T03:08:44.013177Z","end_time":"2023-04-22T03:08:44.047114Z"},"id":"41BEBDE504764ED0BA1278805E14F955","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3","trusted":true},"source":"batch_size = 64\n\n# 创建数据加载器\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)\n\nfor X, y in test_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break","outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n","Shape of y: torch.Size([64]) torch.int64\n"]}],"execution_count":5},{"cell_type":"markdown","metadata":{"id":"437D325D19394D638F78188B153D391C","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"## 1.3 创建模型  \n\n在PyTorch中定义神经网络，我们创建一个继承自`nn.Module`的类。  \n\n我们在`__init__`函数中定义网络的层，并在`forward`函数中指定数据如何通过网络。为了加速神经网络的操作，我们将其移动到GPU或MPS（如果有）。  \n\n获取用于训练的CPU、GPU或MPS设备。"},{"cell_type":"code","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2023-04-22T03:11:09.247986Z","end_time":"2023-04-22T03:11:09.366216Z"},"id":"6F1127DCD79542D594A5211DF6C52782","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3","trusted":true},"source":"# 选择CPU、GPU或MPS设备进行训练\ndevice = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")\n\n# 定义模型\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = NeuralNetwork().to(device)\nprint(model)","outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}],"execution_count":6},{"cell_type":"markdown","metadata":{"id":"BA1C51BD152A4B8B940E48201F52D61B","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"## 1.4 优化模型参数  \n\n要训练一个模型，我们需要一个`损失函数`和一个`优化器`。"},{"cell_type":"code","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2023-04-22T03:12:06.846046Z","end_time":"2023-04-22T03:12:06.868923Z"},"id":"22F1BF7865D64F7C9393EB2B2534ECEB","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3","trusted":true},"source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)","outputs":[],"execution_count":7},{"cell_type":"markdown","metadata":{"id":"F7B55529851E46C686CB2EEB648AB97B","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"在单个训练循环中，模型对训练数据集进行预测（以批次形式提供），并通过反向传播预测误差来调整模型的参数。"},{"cell_type":"code","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2023-04-22T03:13:13.724610Z","end_time":"2023-04-22T03:13:13.741647Z"},"id":"2CE3041B0FE14ACFA4606DADDACD9D98","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3","trusted":true},"source":"def train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # 计算预测误差\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # 反向传播\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), (batch + 1) * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")","outputs":[],"execution_count":8},{"cell_type":"markdown","metadata":{"id":"C1CB375AD72C4C3F9EE5BEB82791474E","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"我们还会对模型在测试数据集上的表现进行检查，以确保其学习效果。"},{"cell_type":"code","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2023-04-22T03:13:28.175786Z","end_time":"2023-04-22T03:13:28.208636Z"},"id":"912585F1F58A44179BCF4944F7CABE7A","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3","trusted":true},"source":"def test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","outputs":[],"execution_count":9},{"cell_type":"markdown","metadata":{"id":"15CB11A26A934C90B504A3FAC3B2B4C8","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"训练过程会进行多轮迭代（epoch）。在每轮迭代中，模型会学习参数以提高预测准确性。我们会在每轮迭代结束后打印模型的准确率和损失值，并希望看到准确率逐步提高，损失值逐步减小。"},{"cell_type":"code","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2023-04-22T03:13:55.538691Z","end_time":"2023-04-22T03:14:32.382807Z"},"id":"3DCDBFB4CCDD4ABA88E19E364FCECB24","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3","trusted":true},"source":"epochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\"Done!\")","outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","-------------------------------\n","loss: 2.311305  [   64/60000]\n","loss: 2.296385  [ 6464/60000]\n","loss: 2.277378  [12864/60000]\n","loss: 2.266208  [19264/60000]\n","loss: 2.256758  [25664/60000]\n","loss: 2.226165  [32064/60000]\n","loss: 2.229622  [38464/60000]\n","loss: 2.204165  [44864/60000]\n","loss: 2.206017  [51264/60000]\n","loss: 2.160655  [57664/60000]\n","Test Error: \n"," Accuracy: 44.9%, Avg loss: 2.163659 \n","\n","Epoch 2\n","-------------------------------\n","loss: 2.182999  [   64/60000]\n","loss: 2.172259  [ 6464/60000]\n","loss: 2.123006  [12864/60000]\n","loss: 2.131096  [19264/60000]\n","loss: 2.080843  [25664/60000]\n","loss: 2.032379  [32064/60000]\n","loss: 2.048243  [38464/60000]\n","loss: 1.988958  [44864/60000]\n","loss: 2.000666  [51264/60000]\n","loss: 1.914852  [57664/60000]\n","Test Error: \n"," Accuracy: 55.7%, Avg loss: 1.919090 \n","\n","Epoch 3\n","-------------------------------\n","loss: 1.964226  [   64/60000]\n","loss: 1.931629  [ 6464/60000]\n","loss: 1.827652  [12864/60000]\n","loss: 1.851110  [19264/60000]\n","loss: 1.735007  [25664/60000]\n","loss: 1.699753  [32064/60000]\n","loss: 1.699398  [38464/60000]\n","loss: 1.618290  [44864/60000]\n","loss: 1.644334  [51264/60000]\n","loss: 1.519323  [57664/60000]\n","Test Error: \n"," Accuracy: 58.4%, Avg loss: 1.542727 \n","\n","Epoch 4\n","-------------------------------\n","loss: 1.620878  [   64/60000]\n","loss: 1.577959  [ 6464/60000]\n","loss: 1.430541  [12864/60000]\n","loss: 1.488146  [19264/60000]\n","loss: 1.358712  [25664/60000]\n","loss: 1.362391  [32064/60000]\n","loss: 1.358066  [38464/60000]\n","loss: 1.296867  [44864/60000]\n","loss: 1.334142  [51264/60000]\n","loss: 1.222562  [57664/60000]\n","Test Error: \n"," Accuracy: 62.8%, Avg loss: 1.252835 \n","\n","Epoch 5\n","-------------------------------\n","loss: 1.337895  [   64/60000]\n","loss: 1.314959  [ 6464/60000]\n","loss: 1.145551  [12864/60000]\n","loss: 1.247177  [19264/60000]\n","loss: 1.114135  [25664/60000]\n","loss: 1.145057  [32064/60000]\n","loss: 1.154537  [38464/60000]\n","loss: 1.105079  [44864/60000]\n","loss: 1.145880  [51264/60000]\n","loss: 1.059853  [57664/60000]\n","Test Error: \n"," Accuracy: 64.4%, Avg loss: 1.080426 \n","\n","Done!\n"]}],"execution_count":10},{"cell_type":"markdown","metadata":{"id":"69D499C29E4347568FE44785877EB1E1","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"##  1.5 模型保存  \n\n保存模型的常见方法是将内部状态字典（包含模型参数）序列化。"},{"cell_type":"code","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2023-04-22T03:14:47.649923Z","end_time":"2023-04-22T03:14:47.696277Z"},"id":"63E9750E8EC9476A8F2F19CB4E26FB25","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3","trusted":true},"source":"torch.save(model.state_dict(), \"model.pth\")\nprint(\"Saved PyTorch Model State to model.pth\")","outputs":[{"name":"stdout","output_type":"stream","text":["Saved PyTorch Model State to model.pth\n"]}],"execution_count":11},{"cell_type":"markdown","metadata":{"id":"19696EFCD3CA472E876DD1F6FED65FF3","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"## 1.6 模型加载  \n\n加载模型的过程包括重新创建模型结构并将状态字典加载到其中。"},{"cell_type":"code","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2023-04-22T03:15:12.698807Z","end_time":"2023-04-22T03:15:12.749462Z"},"id":"0374DC91D7FE4FED9210AF5E74FDC8DA","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3","trusted":true},"source":"model = NeuralNetwork()\nmodel.load_state_dict(torch.load(\"model.pth\"))","outputs":[{"data":{"text/plain":"<All keys matched successfully>"},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"execution_count":12},{"cell_type":"markdown","metadata":{"id":"0FF5E37D98E24EA4996E69A1F54E4EB8","runtime":{"status":"default","execution_status":null},"jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3"},"source":"现在可以使用这个模型进行预测了。"},{"cell_type":"code","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2023-04-22T03:15:33.829006Z","end_time":"2023-04-22T03:15:33.877098Z"},"id":"AA711BBEBD1C48429672609DA6D6C1D1","jupyter":{},"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"6442e9d50aea3eb5dad984f3","trusted":true},"source":"classes = [\n    \"T-shirt/top\",\n    \"Trouser\",\n    \"Pullover\",\n    \"Dress\",\n    \"Coat\",\n    \"Sandal\",\n    \"Shirt\",\n    \"Sneaker\",\n    \"Bag\",\n    \"Ankle boot\",\n]\n\nmodel.eval()\nx, y = test_data[0][0], test_data[0][1]\nwith torch.no_grad():\n    pred = model(x)\n    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')","outputs":[{"name":"stdout","output_type":"stream","text":["Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"]}],"execution_count":13}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}